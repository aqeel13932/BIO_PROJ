{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'aqeel'\n",
    "'''Train and evaluate a simple MLP on the Souq.com Reviews newswire topic classification task.\n",
    "GPU run command:\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python examples/NNClassifiyReviews.py\n",
    "CPU run command:\n",
    "    python examples/NNClassifiyReviews.py\n",
    "'''\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model,Model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.layers.recurrent import LSTM\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#For the baseline\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from ALutils import Calculate_Score,RANK\n",
    "%matplotlib inline\n",
    "np.random.seed(1377)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "ftest = pd.read_csv('../Data/test.csv')\n",
    "#ftest[ftest.columns[[0]+[i for i in range(10,18)]]]\n",
    "#train.head()\n",
    "def GetData(ds):#, splitper=0.2): Splitter is stopped \n",
    "    np.random.seed(1337)\n",
    "    #Convert The Percentage to split point\n",
    "    splitper = 50 #int(math.floor(splitper * ds.shape[0] + 1))\n",
    "\n",
    "    #Shuffle the list\n",
    "    #Shuffle is stopped so we can get stable measurements\n",
    "    #ds = ds.iloc[np.random.permutation(len(ds))]\n",
    "    \n",
    "    #Get tarin,test\n",
    "    ls = [i for i in range(10,18)]\n",
    "    ls+=[0,2]\n",
    "    x_train = ds.iloc[splitper:][np.delete(ds.columns, ls)]\n",
    "    y_train = ds.iloc[splitper:][ds.columns[10:18]]\n",
    "    x_test = ds.iloc[:splitper][np.delete(ds.columns, ls)]\n",
    "    y_test = ds.iloc[:splitper][ds.columns[10:18]]\n",
    "    return (x_train.as_matrix(),y_train.as_matrix()),(x_test.as_matrix(),y_test.as_matrix()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "train: (9235, 24) (9235, 8)\n",
      "test:  (50, 24) (50, 8)\n"
     ]
    }
   ],
   "source": [
    "#1-inf\n",
    "batch_size = 1\n",
    "#1-inf\n",
    "nb_epoch = 1\n",
    "#Done\n",
    "#SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax\n",
    "theoptimizer = 'adam'\n",
    "#DONE\n",
    "#1-inf\n",
    "layernodes = 128\n",
    "#DONE\n",
    "#0.1-0.9\n",
    "thedropout =0.5\n",
    "#DONE\n",
    "#softmax,softplus,relu,tanh,sigmoid,hard_sigmoid,linear,\n",
    "FirstActivation = 'relu'\n",
    "SecondActivation='sigmoid'\n",
    "#DONE\n",
    "#mean_squared_error / mse,root_mean_squared_error / rmse,mean_absolute_error / mae,mean_absolute_percentage_error / mape\n",
    "#mean_squared_logarithmic_error / msle,squared_hinge, hinge,binary_crossentropy: Also known as logloss,categorical_crossentropy: Also known as multiclass logloss. Note: using this objective requires that your labels are binary arrays of shape (nb_samples, nb_classes).\n",
    "#poisson: mean of (predictions - targets * log(predictions))# cosine_proximity: the opposite (negative) of the mean cosine proximity between predictions and targets.\n",
    "theloss='mse'\n",
    "#======================\n",
    "print('Loading data...')\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) =GetData()\n",
    "(x_train,y_train),(x_test,y_test) = GetData(train)\n",
    "#y_train = y_train[:,0]\n",
    "#y_test = y_test[:,0]\n",
    "print('train:',x_train.shape,y_train.shape)\n",
    "print('test: ',x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(128,init='normal', input_dim=x_train.shape[1]))\n",
    "model.add(Activation(FirstActivation))\n",
    "model.add(Dropout(thedropout))\n",
    "model.add(Dense(8,init='normal'))\n",
    "model.add(Activation(SecondActivation))\n",
    "model.compile(loss=theloss, optimizer=theoptimizer,metrics=[theloss])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint('output_files/Model_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='min')\n",
    "history = model.fit(x_train, y_train, nb_epoch=nb_epoch,callbacks=[early_stopping, model_checkpoint], batch_size=batch_size,verbose=1, validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "#results.write(','+str(score[1])+','+str(max(history.history.get('acc'))))\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Score: 33.16822\n",
      "Current Score: 16.81074\n"
     ]
    }
   ],
   "source": [
    "org = RANK(y_test)\n",
    "print('Perfect Score:',Calculate_Score(org,org))\n",
    "#bm = load_model('output_files/t0/Model_01-106548.69.h5')\n",
    "#model = load_model('output_files/Model_NN:2_67-0.12.h5')\n",
    "pred = model.predict(x_test)\n",
    "pred = RANK(pred)\n",
    "print('Current Score:',Calculate_Score(pred,org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train,(x_train.shape[0],1,x_train.shape[1]))\n",
    "x_test = np.reshape(x_test,(x_test.shape[0],1,x_test.shape[1]))\n",
    "model = Sequential()  \n",
    "model.add(LSTM(300,input_shape=(1,24),return_sequences=False))  \n",
    "model.add(Dense(100,init='normal')) \n",
    "model.add(Dense(8,init='normal'))  \n",
    "model.add(Activation(\"linear\"))  \n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8311 samples, validate on 924 samples\n",
      "Epoch 1/1\n",
      "8311/8311 [==============================] - 117s - loss: 0.0683 - val_loss: 0.0795\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint('output_files/Model_LSTM_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='min')\n",
    "history = model.fit(x_train, y_train, nb_epoch=nb_epoch,callbacks=[early_stopping, model_checkpoint], batch_size=batch_size,verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "model = load_model('output_files/models/model_71-0.13.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "y_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x = model.predict(x_test)\n",
    "rmse = ((y_test[:,0] - x) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure()\n",
    "plt.plot([1],y_test[62,0],color='r')\n",
    "plt.plot([1],x[62],color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "np.where(rmse==np.min(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.scatter(range(1,rmse.shape[0]+1),rmse,color='b')\n",
    "ax.set_ylim((0,1))\n",
    "ax.set_xlim((0,1900))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "check = 'what the f**k'\n",
    "print check\n",
    "check = clean_str(check)\n",
    "print check\n",
    "#tokenizer.fit_on_texts(check)\n",
    "#Sequence The Training and Testing Set\n",
    "check = tokenizer.texts_to_sequences(check)\n",
    "print check\n",
    "check = tokenizer.sequences_to_matrix(check, mode=sequencemode)\n",
    "print check\n",
    "#model.predict_classes(x_train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model.save('Models/model_{}.h5'.format(sequencemode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "clss = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with open('Models/performance_{}.txt'.format(sequencemode),'w') as f:\n",
    "    f.write('Accuracy,PPrecision,NPrecision,Precall,Nrecall,\\n')\n",
    "    f.write('{},{},{},{},{}\\n'.format(Accuracy,PPrecision,NPrecision,Precall,Nrecall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
